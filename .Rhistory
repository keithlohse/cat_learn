pPositivehtn=1-pnorm((htermht+ES)/err)
TypeIm1=(pPositiven1+pPositivep1)*pVar*100+TypeIm1
# integrate over all possible sample variances to get the probability
# of incurring the specific MBI inference (e.g., ">=75% beneficial" for each sample size;
TypeIm2=(pPositiven2+pPositivep2)*pVar*100+TypeIm2;
TypeIht=(pPositivehtn+pPositivehtp)*pVar*100+TypeIht;
}
sim_errors$TypeIm1[c]= TypeIm1
sim_errors$TypeIm2[c]= TypeIm2
sim_errors$TypeIht[c]= TypeIht
}
head(sim_errors, 20)
plot(TypeIm1~group_n, pch=21, bg="purple", data=sim_errors, ylim=c(0,100),
main="Between-Subjects, var = 0.364")
points(TypeIm2~group_n, pch=21, bg="firebrick", data=sim_errors)
points(TypeIht~group_n, pch=21, bg="dodgerblue", data=sim_errors)
## Calculator #2: Simulation for Dependent Samples T-Test ----
## Simulating a Data Set ----
set.seed(17)
var <- 0.364 # Variation of the difference.
deltab <- 0.2 # threshold for benefit
deltah <- 0.2 # threshold for harm
maxrisk <- .05 # maximum risk of harm
ES <- 0 # effect size, must be in the trivial range for a Type 1 error.
thresh1<-0.75 # MBI evidentiary threshold of interest, eg "likely"=.75
thresh2<-0.25 # second MB evidentiary threshold of interest, eg "possible" = 0.25
# Generating a simulated data frame
n<-c(seq(from=5, to=60, by=1))
estvar <- seq(from=.001, to = (3*var), by = .001)
index<-c(seq(from =1, to=length(n), by=1))
sim_errors<-data.frame(index)
head(sim_errors)
c <- 0
for (j in 1:length(n)) {
c <- c + 1
print(c)
sim_errors$group_n[j]<-n[j]
df <- n[j]-1 # degrees of freedom for independent samples t-test
err <- sqrt(var)/sqrt(n[j]) # standard error for independent samples t-test
th=qt((1-maxrisk),df) # T for harm, e.g. 1.64 for 90% CI
tb1=qt(1-thresh1,df) # T for benefit, assuming eg 75% minimum chance benefit (MBI, likely threshold)
tb2=qt(1-thresh2,df) # T for benefit, assuming eg 25% minimum chance benefit (MBI, possible threshold);
thht=qt((1-.025),df) # T for harm, standard hypothesis testing,
# using the fact that MBI collapses to HT when threshold ~0 to calculate
# rates for HT, .05 significance level
TypeIm1=0 # Stores the Type I error for MBI threshold one;
TypeIm2=0 # Stores the Type I error for MBI threshold two;
TypeIht=0 # Stores the Type I error standard HT;
for (i in 1:length(estvar)){
esterr=sqrt(estvar[i])/sqrt(n[j]) # sample standard error;
hterm=(-deltah)+th*esterr # constraint on harm
bterm1=deltab-tb1*esterr # constraint on benefit, threshold 1;
bterm2=deltab-tb2*esterr # constraint on benefit, threshold 2;
htermht=(-.0001)+thht*esterr # constraint on harm for standard hypothesis testing.
# Harm term dominates in all cases for standard HT
pVar=pchisq((df*(estvar[i]+.001)/var),df)-pchisq((df*estvar[i]/var),df)
# probability of each sample variance in .001 increments;
pPositivep1=1-pnorm(((max(hterm,bterm1)-ES)/err));
# the probability of reaching the given MBI threshold
#(eg "clear, >=75% beneficial"). The observed value must be greater than the
# maximum of the harm and benefit constraints
pPositiven1=1-pnorm((max(hterm,bterm1)+ES)/err) # the probability of reaching
# the given MBI threshold on the negative side
pPositivep2=1-pnorm((max(hterm,bterm2)-ES)/err)
# repeat for second MBI threshold;
pPositiven2=1-pnorm((max(hterm,bterm2)+ES)/err)
pPositivehtp=1-pnorm((htermht-ES)/err)
# repeat for standard HT (constraint term always bigger)
pPositivehtn=1-pnorm((htermht+ES)/err)
TypeIm1=(pPositiven1+pPositivep1)*pVar*100+TypeIm1
# integrate over all possible sample variances to get the probability
# of incurring the specific MBI inference (e.g., ">=75% beneficial" for each sample size;
TypeIm2=(pPositiven2+pPositivep2)*pVar*100+TypeIm2;
TypeIht=(pPositivehtn+pPositivehtp)*pVar*100+TypeIht;
}
sim_errors$TypeIm1[c]= TypeIm1
sim_errors$TypeIm2[c]= TypeIm2
sim_errors$TypeIht[c]= TypeIht
}
head(sim_errors, 20)
plot(TypeIm1~group_n, pch=21, bg="purple", data=sim_errors, ylim=c(0,100),
main="Within-Subject, var = 0.8")
plot(TypeIm1~group_n, pch=21, bg="purple", data=sim_errors, ylim=c(0,100),
main=expression("Within-Subject, var = "*var))
plot(TypeIm1~group_n, pch=21, bg="purple", data=sim_errors, ylim=c(0,100),
main=expression("Within-Subject, var = "var))
plot(TypeIm1~group_n, pch=21, bg="purple", data=sim_errors, ylim=c(0,100),
main=paste("Within-Subject, var = ", var))
plot(TypeIm1~group_n, pch=21, bg="purple", data=sim_errors, ylim=c(0,100),
main=paste("Between-Subjects, var = ", var))
points(TypeIm2~group_n, pch=21, bg="firebrick", data=sim_errors)
points(TypeIht~group_n, pch=21, bg="dodgerblue", data=sim_errors)
## Calculator #2: Simulation for Dependent Samples T-Test ----
## Simulating a Data Set ----
set.seed(17)
var <- 0.364 # Variation of the difference.
deltab <- 0.2 # threshold for benefit
deltah <- 0.2 # threshold for harm
maxrisk <- .05 # maximum risk of harm
ES <- 0 # effect size, must be in the trivial range for a Type 1 error.
thresh1<-0.75 # MBI evidentiary threshold of interest, eg "likely"=.75
thresh2<-0.25 # second MB evidentiary threshold of interest, eg "possible" = 0.25
# Generating a simulated data frame
n<-c(seq(from=5, to=60, by=1))
estvar <- seq(from=.001, to = (3*var), by = .001)
index<-c(seq(from =1, to=length(n), by=1))
sim_errors<-data.frame(index)
head(sim_errors)
c <- 0
for (j in 1:length(n)) {
c <- c + 1
print(c)
sim_errors$group_n[j]<-n[j]
df <- n[j]-1 # degrees of freedom for independent samples t-test
err <- sqrt(var)/sqrt(n[j]) # standard error for independent samples t-test
th=qt((1-maxrisk),df) # T for harm, e.g. 1.64 for 90% CI
tb1=qt(1-thresh1,df) # T for benefit, assuming eg 75% minimum chance benefit (MBI, likely threshold)
tb2=qt(1-thresh2,df) # T for benefit, assuming eg 25% minimum chance benefit (MBI, possible threshold);
thht=qt((1-.025),df) # T for harm, standard hypothesis testing,
# using the fact that MBI collapses to HT when threshold ~0 to calculate
# rates for HT, .05 significance level
TypeIm1=0 # Stores the Type I error for MBI threshold one;
TypeIm2=0 # Stores the Type I error for MBI threshold two;
TypeIht=0 # Stores the Type I error standard HT;
for (i in 1:length(estvar)){
esterr=sqrt(estvar[i])/sqrt(n[j]) # sample standard error;
hterm=(-deltah)+th*esterr # constraint on harm
bterm1=deltab-tb1*esterr # constraint on benefit, threshold 1;
bterm2=deltab-tb2*esterr # constraint on benefit, threshold 2;
htermht=(-.0001)+thht*esterr # constraint on harm for standard hypothesis testing.
# Harm term dominates in all cases for standard HT
pVar=pchisq((df*(estvar[i]+.001)/var),df)-pchisq((df*estvar[i]/var),df)
# probability of each sample variance in .001 increments;
pPositivep1=1-pnorm(((max(hterm,bterm1)-ES)/err));
# the probability of reaching the given MBI threshold
#(eg "clear, >=75% beneficial"). The observed value must be greater than the
# maximum of the harm and benefit constraints
pPositiven1=1-pnorm((max(hterm,bterm1)+ES)/err) # the probability of reaching
# the given MBI threshold on the negative side
pPositivep2=1-pnorm((max(hterm,bterm2)-ES)/err)
# repeat for second MBI threshold;
pPositiven2=1-pnorm((max(hterm,bterm2)+ES)/err)
pPositivehtp=1-pnorm((htermht-ES)/err)
# repeat for standard HT (constraint term always bigger)
pPositivehtn=1-pnorm((htermht+ES)/err)
TypeIm1=(pPositiven1+pPositivep1)*pVar*100+TypeIm1
# integrate over all possible sample variances to get the probability
# of incurring the specific MBI inference (e.g., ">=75% beneficial" for each sample size;
TypeIm2=(pPositiven2+pPositivep2)*pVar*100+TypeIm2;
TypeIht=(pPositivehtn+pPositivehtp)*pVar*100+TypeIht;
}
sim_errors$TypeIm1[c]= TypeIm1
sim_errors$TypeIm2[c]= TypeIm2
sim_errors$TypeIht[c]= TypeIht
}
head(sim_errors, 20)
plot(TypeIm1~group_n, pch=21, bg="purple", data=sim_errors, ylim=c(0,100),
main=paste("Within-Subject, var = ", var))
points(TypeIm2~group_n, pch=21, bg="firebrick", data=sim_errors)
points(TypeIht~group_n, pch=21, bg="dodgerblue", data=sim_errors)
var(sim_errors$TypeIm1)
var(sim_errors$TypeIm2)
var(sim_errors$TypeIht)
## Calculator #1: Simulation for Independent Samples T-Test ----
## Simulating a Data Set ----
set.seed(17)
var <- 0.364 # Between-person (within group) variance for an independent samples design
deltab <- 0.2 # threshold for benefit
deltah <- 0.2 # threshold for harm
maxrisk <- 0.05 # maximum risk of harm
ES <- 0.0 # effect size, must be in the trivial range for a Type 1 error.
thresh1<-0.75 # MBI evidentiary threshold of interest, eg "likely"=.75
thresh2<-0.25 # second MB evidentiary threshold of interest, eg "possible" = 0.25
# Generating a simulated data frame
n<-c(seq(from=5, to=60, by=1))
estvar <- seq(from=.001, to = (3*var), by = .001)
index<-c(seq(from =1, to=length(n), by=1))
sim_errors<-data.frame(index)
head(sim_errors)
c <- 0
for (j in 1:length(n)) {
c <- c + 1
print(c)
sim_errors$group_n[j]<-n[j]
df <- 2*n[j]-2 # degrees of freedom for independent samples t-test
err <- sqrt(2)*sqrt(var)/sqrt(n[j]) # standard error for independent samples t-test
th=qt((1-maxrisk),df) # T for harm, e.g. 1.64 for 90% CI
tb1=qt(1-thresh1,df) # T for benefit, assuming eg 75% minimum chance benefit (MBI, likely threshold)
tb2=qt(1-thresh2,df) # T for benefit, assuming eg 25% minimum chance benefit (MBI, possible threshold);
thht=qt((1-.025),df) # T for harm, standard hypothesis testing,
# using the fact that MBI collapses to HT when threshold ~0 to calculate
# rates for HT, .05 significance level
TypeIm1=0 # Stores the Type I error for MBI threshold one;
TypeIm2=0 # Stores the Type I error for MBI threshold two;
TypeIht=0 # Stores the Type I error standard HT;
for (i in 1:length(estvar)){
esterr=sqrt(estvar[i]*2/n[j]) # sample standard error;
hterm=(-deltah)+th*esterr # constraint on harm
bterm1=deltab-tb1*esterr # constraint on benefit, threshold 1;
bterm2=deltab-tb2*esterr # constraint on benefit, threshold 2;
htermht=(-.0001)+thht*esterr # constraint on harm for standard hypothesis testing.
# Harm term dominates in all cases for standard HT
pVar=pchisq((df*(estvar[i]+.001)/var),df)-pchisq((df*estvar[i]/var),df)
# probability of each sample variance in .001 increments;
pPositivep1=1-pnorm(((max(hterm,bterm1)-ES)/err));
# the probability of reaching the given MBI threshold
#(eg "clear, >=75% beneficial"). The observed value must be greater than the
# maximum of the harm and benefit constraints
pPositiven1=1-pnorm((max(hterm,bterm1)+ES)/err) # the probability of reaching
# the given MBI threshold on the negative side
pPositivep2=1-pnorm((max(hterm,bterm2)-ES)/err)
# repeat for second MBI threshold;
pPositiven2=1-pnorm((max(hterm,bterm2)+ES)/err)
pPositivehtp=1-pnorm((htermht-ES)/err)
# repeat for standard HT (constraint term always bigger)
pPositivehtn=1-pnorm((htermht+ES)/err)
TypeIm1=(pPositiven1+pPositivep1)*pVar*100+TypeIm1
# integrate over all possible sample variances to get the probability
# of incurring the specific MBI inference (e.g., ">=75% beneficial" for each sample size;
TypeIm2=(pPositiven2+pPositivep2)*pVar*100+TypeIm2;
TypeIht=(pPositivehtn+pPositivehtp)*pVar*100+TypeIht;
}
sim_errors$TypeIm1[c]= TypeIm1
sim_errors$TypeIm2[c]= TypeIm2
sim_errors$TypeIht[c]= TypeIht
}
head(sim_errors, 20)
plot(TypeIm1~group_n, pch=21, bg="purple", data=sim_errors, ylim=c(0,100),
main=paste("Between-Subjects, var = ", var))
points(TypeIm2~group_n, pch=21, bg="firebrick", data=sim_errors)
points(TypeIht~group_n, pch=21, bg="dodgerblue", data=sim_errors)
## Calculator #1: Simulation for Independent Samples T-Test ----
## Simulating a Data Set ----
set.seed(17)
var <- 0.8 # Between-person (within group) variance for an independent samples design
deltab <- 0.2 # threshold for benefit
deltah <- 0.2 # threshold for harm
maxrisk <- 0.05 # maximum risk of harm
ES <- 0.0 # effect size, must be in the trivial range for a Type 1 error.
thresh1<-0.75 # MBI evidentiary threshold of interest, eg "likely"=.75
thresh2<-0.25 # second MB evidentiary threshold of interest, eg "possible" = 0.25
# Generating a simulated data frame
n<-c(seq(from=5, to=60, by=1))
estvar <- seq(from=.001, to = (3*var), by = .001)
index<-c(seq(from =1, to=length(n), by=1))
sim_errors<-data.frame(index)
head(sim_errors)
c <- 0
for (j in 1:length(n)) {
c <- c + 1
print(c)
sim_errors$group_n[j]<-n[j]
df <- 2*n[j]-2 # degrees of freedom for independent samples t-test
err <- sqrt(2)*sqrt(var)/sqrt(n[j]) # standard error for independent samples t-test
th=qt((1-maxrisk),df) # T for harm, e.g. 1.64 for 90% CI
tb1=qt(1-thresh1,df) # T for benefit, assuming eg 75% minimum chance benefit (MBI, likely threshold)
tb2=qt(1-thresh2,df) # T for benefit, assuming eg 25% minimum chance benefit (MBI, possible threshold);
thht=qt((1-.025),df) # T for harm, standard hypothesis testing,
# using the fact that MBI collapses to HT when threshold ~0 to calculate
# rates for HT, .05 significance level
TypeIm1=0 # Stores the Type I error for MBI threshold one;
TypeIm2=0 # Stores the Type I error for MBI threshold two;
TypeIht=0 # Stores the Type I error standard HT;
for (i in 1:length(estvar)){
esterr=sqrt(estvar[i]*2/n[j]) # sample standard error;
hterm=(-deltah)+th*esterr # constraint on harm
bterm1=deltab-tb1*esterr # constraint on benefit, threshold 1;
bterm2=deltab-tb2*esterr # constraint on benefit, threshold 2;
htermht=(-.0001)+thht*esterr # constraint on harm for standard hypothesis testing.
# Harm term dominates in all cases for standard HT
pVar=pchisq((df*(estvar[i]+.001)/var),df)-pchisq((df*estvar[i]/var),df)
# probability of each sample variance in .001 increments;
pPositivep1=1-pnorm(((max(hterm,bterm1)-ES)/err));
# the probability of reaching the given MBI threshold
#(eg "clear, >=75% beneficial"). The observed value must be greater than the
# maximum of the harm and benefit constraints
pPositiven1=1-pnorm((max(hterm,bterm1)+ES)/err) # the probability of reaching
# the given MBI threshold on the negative side
pPositivep2=1-pnorm((max(hterm,bterm2)-ES)/err)
# repeat for second MBI threshold;
pPositiven2=1-pnorm((max(hterm,bterm2)+ES)/err)
pPositivehtp=1-pnorm((htermht-ES)/err)
# repeat for standard HT (constraint term always bigger)
pPositivehtn=1-pnorm((htermht+ES)/err)
TypeIm1=(pPositiven1+pPositivep1)*pVar*100+TypeIm1
# integrate over all possible sample variances to get the probability
# of incurring the specific MBI inference (e.g., ">=75% beneficial" for each sample size;
TypeIm2=(pPositiven2+pPositivep2)*pVar*100+TypeIm2;
TypeIht=(pPositivehtn+pPositivehtp)*pVar*100+TypeIht;
}
sim_errors$TypeIm1[c]= TypeIm1
sim_errors$TypeIm2[c]= TypeIm2
sim_errors$TypeIht[c]= TypeIht
}
head(sim_errors, 20)
plot(TypeIm1~group_n, pch=21, bg="purple", data=sim_errors, ylim=c(0,100),
main=paste("Between-Subjects, var = ", var))
points(TypeIm2~group_n, pch=21, bg="firebrick", data=sim_errors)
points(TypeIht~group_n, pch=21, bg="dodgerblue", data=sim_errors)
## Opening libraries -----------------------------------------------------------
library("ggplot2"); library("lme4"); library("lmerTest");library("dplyr");
library("car")
## Set working Directory ------------------------------------------------
getwd()
setwd("~/GitHub/cat_learn/")
getwd()
# let's see what is in the data folder
list.files()
##  Create a new smaller dataframe, REST, PRE, PRAC ----------------------------
DATA <- read.csv("./data_MASTER.csv",
header = TRUE, sep=",",na.strings=c("","NA"))
head(DATA)
DATA$trial.c<-(DATA$trial-mean(DATA$trial))/10 #1-unit change = 10 trials
DATA$stim_cat<-factor(DATA$stim_cat)
DATA$resp_cat<-factor(DATA$resp_cat)
DATA$next_resp_same_cat<-factor(DATA$next_resp_same_cat)
DATA$prev_resp_same_cat<-factor(DATA$prev_resp_same_cat)
# Removing NAs for missed responses (1 exclusion)
DAT2<-subset(DATA, correct != "NA")
# Removing NAs for artifact rejection in the RewP (92 exclusions)
DAT2<-subset(DAT2, RewP != "NA")
## Removing statistical outliers in the data -----------------------------------
# Removing RewP Outliers ----
summary(DAT2$RewP)
sd(DAT2$RewP)
quantile(DAT2$RewP, c(0.0005,0.50,0.9995))
plot(density(DAT2$RewP))
DAT2<-subset(DAT2, RewP >= -50)
DAT2<-subset(DAT2, RewP <= 50)
plot(density(DAT2$RewP))
# Removing NAs for missed responses (1 exclusion)
DAT2<-subset(DATA, correct != "NA")
# Removing NAs for artifact rejection in the RewP (92 exclusions)
DAT2<-subset(DAT2, RewP != "NA")
## Removing statistical outliers in the data -----------------------------------
# Removing RewP Outliers ----
summary(DAT2$RewP)
sd(DAT2$RewP)
quantile(DAT2$RewP, c(0.0005,0.50,0.9995))
plot(density(DAT2$RewP))
DAT2<-subset(DAT2, RewP >= -50)
DAT2<-subset(DAT2, RewP <= 50)
plot(density(DAT2$RewP))
## Merging the acquistion data with the learning data --------------------------
LEARN <- read.csv("./data_POST_AVE.csv",
header = TRUE, sep=",",na.strings=c("","NA"))
head(LEARN)
# selecting the subset of columns we want (ignoring individual categories for now)
head(LEARN[c(1,2,8,14,15,21,27,28,29,30,36:46)])
LEARN2<-LEARN[c(1,2,8,14,15,21,27,28,29,30,36:46)]
COMB <- merge(DAT2, LEARN2, by ="subID")
head(COMB)
## -------------------------- Overall Analyses ---------------------------------
## ------------------------ Single Trial Analyses ------------------------------
## Improvement Over Time During Practice ---------------------------------------
## Does accuracy improve over time?
head(COMB)
COMB$hit_binom<-(COMB$hit+1)/2
COMB$sterile.c<-(as.numeric(COMB$acq_cond)-1.5)*2
summary(as.factor(COMB$sterile))
summary(COMB$trial.c)
contrasts(COMB$stim_cat)<-contr.poly(5)
p01<-glmer(hit_binom~
# Fixed-effects
1+stim_cat*sterile.c*trial.c+ # adding in interaction
# Random-effects
(1+trial.c|subID)+(1|subID:stim_cat), data=COMB, family = binomial)
summary(p01)
Anova(p01, type=c("III"))
## Aggregate RewP --------------------------------------------------------------
POST <- read.csv("./data_POST_LONG.csv",
header = TRUE, sep=",",na.strings=c("","NA"))
head(POST)
AVE<-subset(POST, post_cond=="game" & rotated=="-1")
AVE<-subset(AVE, RewP_diff_Windows!="NA")
summary(AVE$RewP_diff_Windows)
m02<-lm(RewP_diff_Windows~sterile, data=AVE)
head(POST)
head(POST)
as.numeric(POST$acq_cond)
POST$sterile.c<-(as.numeric(POST$acq_cond)-1.5)*2
head(POST)
AVE<-subset(POST, post_cond=="game" & rotated=="-1")
AVE<-subset(AVE, RewP_diff_Windows!="NA")
summary(AVE$RewP_diff_Windows)
m02<-lm(RewP_diff_Windows~sterile.c, data=AVE)
summary(m02)
anova(m02)
t.test(RewP_diff_Windows~acq_cond, data=AVE, paired=FALSE, var.equal=TRUE)
## Primary Analysis: Engagement --------------------------------------------------
head(AVE)
m05<-lm(eng_total~acq_cond, data=AVE)
summary(m05)
t.test(eng_total~acq_cond, data=AVE ,var.equal=TRUE)
head(LEARN)
m05b<-(lm(rt_correct~acq_cond+eng_total+acq_total, data=LEARN))
head(LEARN)
head(LEARN)
m05b<-(lm(rt_correct~acq_cond+eng_total+acq_total, data=LEARN))
summary(m05b)
## Primary Analysis: Engagement --------------------------------------------------
head(AVE)
m05<-lm(eng_total~acq_cond, data=AVE)
summary(m05)
## Practice Performance as a funciton of RewP ----------------------------------
head(LEARN)
LEARN$sterile.c<-(as.numeric(LEARN$acq_cond)-1.5)*2
m00a<-lm(sqrt(acq_total)~sterile.c+RewP_diff_Windows, data=LEARN)
summary(m00a)
m00a<-lm(sqrt(acq_total)~sterile.c+RewP_diff_Windows, data=LEARN)
summary(m00a)
m00b<-lm(sqrt(acq_total)~sterile+RewP_hit_ave_Windows+RewP_miss_ave_Windows,
data=LEARN)
m00b<-lm(sqrt(acq_total)~sterile.c+RewP_hit_ave_Windows+RewP_miss_ave_Windows,
data=LEARN)
summary(m00b)
## Sequential Effects on the RewP -----------------------------------------------
head(COMB)
SEQ <- subset(COMB, prev_resp_hit != "NA")
summary(as.factor(SEQ$sterile.c))
summary(as.factor(SEQ$hit))
summary(as.factor(SEQ$prev_resp_hit))
s01<-lmer(RewP~
# Fixed-effects
1+sterile.c*trial.c*hit*prev_resp_hit+ # adding in interaction
# Random-effects
(1+trial.c|subID)+(1|subID:stim_cat), data=SEQ, REML=FALSE)
summary(s01)
## Figure 6A: Sequential Effect on RewP ----------------------------------------
head(COMB)
labels <- c(correct = "Previous Correct", incorrect = "Previous Incorrect")
ggplot(data = SEQ,
mapping = aes(x = correct, y = RewP)) +
geom_jitter(aes(fill=correct), position=position_jitterdodge(dodge.width=1),
pch=21, size=3, alpha = .6) +
geom_boxplot(aes(fill=correct), alpha = .8, notch=FALSE,
col="black", lwd=1, outlier.shape=NA)+
scale_fill_manual(values = c("grey40", "white"))+
facet_wrap(~prev_resp_correct, labeller=labeller(prev_resp_correct=labels))+
scale_x_discrete(name = "Current Response") +
scale_y_continuous(name = expression("sFA ("*mu*"V)"), limits=c(-50,50))+
theme(axis.text=element_text(size=16, colour="black"),
axis.title=element_text(size=16,face="bold"),
strip.text = element_text(size=16, face="bold"),
legend.position = "none")
ggplot(data = SEQ,
mapping = aes(x = trial, y = RewP)) +
geom_point(aes(fill=correct), pch=21, size=3, alpha = .6) +
stat_smooth(aes(lty=prev_resp_correct), col="black", method="lm", lwd = 1.5, se=FALSE)+
facet_wrap(~prev_resp_correct, labeller=labeller(prev_resp_correct=labels))+
scale_x_continuous(name = "Trial Number") +
scale_y_continuous(name = expression("sFA ("*mu*"V)"), limits=c(-50,50))+
scale_linetype_manual(name="Current Response",
breaks=c("correct", "incorrect"),
labels=c("Correct", "Incorrect"),
values = c(1,4))+
scale_fill_manual(name="Current Response",
breaks=c("correct", "incorrect"),
labels=c("Correct", "Incorrect"),
values = c("grey40","white"))+
theme(axis.text=element_text(size=16, colour="black"),
axis.title=element_text(size=16,face="bold"),
legend.text=element_text(size=16),
legend.title=element_text(size=16,face="bold"),
strip.text = element_text(size=16, face="bold"),
legend.position = "bottom")
## Figure 6B: RewP Over Time ---------------------------------------------------
head(SEQ)
ggplot(data = SEQ,
mapping = aes(x = trial, y = RewP)) +
#geom_point(aes(fill=correct), pch=21, size=3, alpha = .6) +
stat_smooth(aes(group=subID, col=prev_resp_correct), method="lm", lwd = 0.75, se=FALSE)+
stat_smooth(aes(lty=prev_resp_correct), col="black", method="lm", lwd = 1.5, se=FALSE)+
facet_wrap(~prev_resp_correct, labeller=labeller(prev_resp_correct=labels))+
scale_x_continuous(name = "Trial Number") +
scale_y_continuous(name = expression("sFA ("*mu*"V)"), limits=c(-50,50))+
scale_linetype_manual(name="Current Response",
breaks=c("correct", "incorrect"),
labels=c("Correct", "Incorrect"),
values = c(1,4))+
scale_fill_manual(name="Current Response",
breaks=c("correct", "incorrect"),
labels=c("Correct", "Incorrect"),
values = c("grey40","white"))+
theme(axis.text=element_text(size=16, colour="black"),
axis.title=element_text(size=16,face="bold"),
legend.text=element_text(size=16),
legend.title=element_text(size=16,face="bold"),
strip.text = element_text(size=16, face="bold"),
legend.position = "bottom")
ggplot(data = SEQ,
mapping = aes(x = trial, y = RewP)) +
#geom_point(aes(fill=correct), pch=21, size=3, alpha = .6) +
stat_smooth(aes(group=subID, col=prev_resp_correct), method="lm", lwd = 0.5, se=FALSE)+
stat_smooth(aes(lty=prev_resp_correct), col="black", method="lm", lwd = 1.5, se=FALSE)+
facet_wrap(~prev_resp_correct, labeller=labeller(prev_resp_correct=labels))+
scale_x_continuous(name = "Trial Number") +
scale_y_continuous(name = expression("sFA ("*mu*"V)"), limits=c(-25,25))+
scale_linetype_manual(name="Current Response",
breaks=c("correct", "incorrect"),
labels=c("Correct", "Incorrect"),
values = c(1,4))+
scale_fill_manual(name="Current Response",
breaks=c("correct", "incorrect"),
labels=c("Correct", "Incorrect"),
values = c("grey40","white"))+
theme(axis.text=element_text(size=16, colour="black"),
axis.title=element_text(size=16,face="bold"),
legend.text=element_text(size=16),
legend.title=element_text(size=16,face="bold"),
strip.text = element_text(size=16, face="bold"),
legend.position = "bottom")
